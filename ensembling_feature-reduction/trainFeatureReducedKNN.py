
"""
 Trains a defined model with a defined ratio of malware samples in each dataset and saves the model afterwards.
"""

#TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
from sklearn import metrics
import matplotlib.pyplot as plt
from tensorflow.keras.utils import plot_model

import os
from random import randint, shuffle
from sklearn.externals import joblib

FILE_MALWARES = '../data/malwares_sha256.txt' # path to file with the SHAs of all malware samples from the dataset
DIR_APP_FEATURES = '../data/apps_feature_indexes/' # directory containing all definition files

# list with all malware samples
MALWARES = []
# list with all cleanware samples
CLEANWARES = []

print("creating list of MALWARES...")
with open(FILE_MALWARES, "r") as file:
    for line in file:
        if line:
            MALWARES.append(line.strip())
print("finished!")

print("creating list of CLEANWARES...")
for filename in os.listdir(DIR_APP_FEATURES):
    if filename not in MALWARES:
        CLEANWARES.append(filename)
print("finished!")


#=========== CLASSIFIER ============== CLASSIFIER ============== CLASSIFIER ===========
#===================================== PARAMETERS =====================================
M = 4109
BATCH_SIZE = 1000
DROPOUT = 0.5
EPOCHS = 10
#======================================================================================
#======================================================================================

def generate_app_set(ratio):
    app_set= []
    # add MALWARES to training data set
    while len(app_set) < (BATCH_SIZE * ratio):
        index = randint(0, len(MALWARES)-1)
        app = MALWARES[index]
        if app not in app_set:
            app_set.append(app)
    # add CLEANWARES to training data set
    while len(app_set) < BATCH_SIZE:
        index = randint(0, len(CLEANWARES)-1)
        app = CLEANWARES[index]
        if app not in app_set:
            app_set.append(app)
    return app_set

def generate_model_input(applist):
    data = np.zeros((len(applist), M), dtype=float)
    labels = np.zeros((len(applist),), dtype=int)

    shuffle(applist)
    for idx, app_sha in enumerate(applist):
        app_sha = app_sha.strip()
        with open(DIR_APP_FEATURES + app_sha, 'r') as app:
            for index in app:
                data[idx][int(index)] = 1.0

        if app_sha in MALWARES:
            labels[idx] = 1
        else:
            labels[idx] = 0

    return data, labels

# path to the directory in that the model should be saved
MODEL_DIR = './models/KNN_{}.sav'
# malware ratio with that the model should be trained
RATIO = 0.3

MODEL_DIR = MODEL_DIR.format(RATIO)
model = KNeighborsClassifier(n_neighbors = 3)

for i in range(5):
    print('-------------------- TRAINING Ratio ({}) --------------------'.format(ratio))
    train_apps = generate_app_set(ratio)
    train_data, train_labels = generate_model_input(train_apps)

    knnmodel.fit(train_data, train_labels)
    # ======================================================================================

    print('-------------------- VALIDATION Ratio ({}) --------------------'.format(ratio))
    val_apps = generate_app_set(ratio)
    val_data, val_labels = generate_model_input(val_apps)
    predictions = model.predict_proba(val_data)
    confusion = metrics.confusion_matrix(val_labels, np.argmax(predictions, axis=1))
    print(confusion)
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    FNR = FN / float(FN+TP)
    FPR = FP / float(FP+TN)
    ACC = (TP + TN) / float(TP+TN+FP+FN)
    print('FP: {}\tFN: {}\t\tTP: {}\tTN: {}'.format(FP,FN,TP,TN))
    print('Accuracy: {}\tFPR: {}\tFNR: {}\n'.format(ACC,FPR,FNR))

# save the model
joblib.dump(MODEL_DIR)
print('\n\n\n')
